{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "613c14b0-2a6a-411d-a84a-a84161b2a022",
   "display_name": "'Python Interactive'"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(open(\"/content/drive/My Drive/Classifier/authenticom_sales.csv\", \"rb\"), delimiter=\",\", skiprows=1, dtype=str)\n",
    "# result = csv.reader(open(\"/content/drive/My Drive/Classifier/authenticom_sales.csv\", \"rb\"), delimiter=\",\")\n",
    "with open(\"authenticom_sales.csv\", newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "data = data[1:]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_split=.25):\n",
    "  # create test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "def grid_search(X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    for activation in ['relu', 'tanh', 'logistic']:\n",
    "        for lr in [.001, .01, .1]:\n",
    "            for hidden_layers in [(10,10), (20, 20), (30)]:\n",
    "                for momentum in [.1, .5, .9]:\n",
    "                    mlp = SKMLPClassifier(hidden_layer_sizes=hidden_layers,\n",
    "                                          activation=activation,\n",
    "                                          momentum=momentum,\n",
    "                                          early_stopping=False,\n",
    "                                          max_iter=1000,\n",
    "                                          learning_rate_init=lr)\n",
    "                    print(\"\\nHidden layer sizes:\", hidden_layers,\n",
    "                          \"Activation fun:\", activation,\n",
    "                          \"Momentum:\", momentum,\n",
    "                          \"Learning rate\", lr)\n",
    "                    mlp.fit(X_train, y_train[:,-1])\n",
    "                    score = mlp.score(X_test, y_test)\n",
    "                    print(\"Score:\", score)\n",
    "                    results.append((activation, lr, hidden_layers, momentum, score))\n",
    "    return results\n",
    "\n",
    "def one_hot_encode(data):\n",
    "  return preprocessing.LabelBinarizer().fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = one_hot_encode(data)\n",
    "data, labels = zip(*[(s[:-1], [s[-1]]) for s in data])\n",
    "X_train, X_test, y_train, y_test = split_data(data, labels)\n",
    "\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(10,10), \n",
    "#                         activation='relu',\n",
    "#                         learning_rate_init=.01,\n",
    "#                         momentum=.9,\n",
    "#                         max_iter=1000,\n",
    "#                         nesterovs_momentum=False,\n",
    "#                         early_stopping=False,\n",
    "#                         alpha=.001)\n",
    "# mlp.fit(X_train,y_train)\n",
    "# print(\"\\nMLP1 SCORE:\", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train')"
   ]
  }
 ]
}